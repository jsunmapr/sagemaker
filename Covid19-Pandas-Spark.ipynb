{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Sparkmagic (PySpark) kernel for this notebook\n",
    "Get csv from internet source and clean it then save to S3 bucket\n",
    "The csv can be read by another nootbook Covid-19-Pandas.ipynb(with conda_python3 kernel) for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from io import StringIO # python3; python2: BytesIO \n",
    "\n",
    "data_url ='https://bit.ly/3d93pa1'\n",
    "\n",
    "pdf = pd.read_csv(data_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transpose and extract selected columns(countries) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf1 = pdf.T.drop(['Country/Region','Province/State','Lat','Long']).iloc[:,[28,116,120,137,201,225]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a 'date' column to df2 and update column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf1['date'] = pd.date_range(start='1/22/2020', periods=len(pdf1), freq='D')\n",
    "pdf1.columns = ['Brazil', 'France', 'Germany', 'Italy', 'Spain', 'US', 'date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pdf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# a scatter plot comparing num_children and num_pets\n",
    "pdf1.plot('date',['US', 'Brazil', 'Italy', 'France', 'Germany'])\n",
    "%matplot plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save pdf1 to S3 as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'mybucket' # already created on S3\n",
    "csv_buffer = StringIO()\n",
    "pdf1.to_csv(csv_buffer)\n",
    "s3_resource = boto3.resource('s3')\n",
    "s3_resource.Object(bucket, 'pandas/cv.csv').put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Pandas dataframe (pdf1) to Spark dataframe (sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "sdf = spark.createDataFrame(pdf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save spark dataframe to S3 with parquet format, this way the schema is preserved, csv doesn't \n",
    "preserve schema, so it will become messy when read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.write.parquet(\"s3a://mybucket/parquet/\",mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now read it back to another spark dataframe sdf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf1 = spark.read.load(\"s3n://mybucket/parquet/\")\n",
    "sdf1.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save sdf to hive table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.createOrReplaceTempView(\"mytempTable\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext.sql(\"drop table if exists CV19\")\n",
    "sqlContext.sql(\"create table if not exists CV19 as select * from mytempTable\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext.sql(\"select * from CV19\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or simply just use %%sql to run the queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from CV19 where US >= 3000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read from csv in S3 to Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3c = boto3.client('s3')\n",
    "obj = s3c.get_object(Bucket= 'mybucket' , Key = \"pandas/cv.csv\")\n",
    "pdf3 = pd.read_csv(io.BytesIO(obj['Body'].read()), encoding='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot out a pie chart using the last row confirmed cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart, where the slices will be ordered and plotted counter-clockwise:\n",
    "labels = 'Brazil', 'France', 'Germany', 'Italy', 'Spain', 'US'\n",
    "confirmed = pdf3.tail(1).iloc[0,1:7]\n",
    "explode = (0, 0, 0, 0, 0, 0.1)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(confirmed, explode=explode, labels=labels, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplot plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the current date when the data is collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pdf3.tail(1).iloc[0,7])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
